metallica<-c("Lars","James","Jason","Kirk")
metalica
print(metallica)
metallica<-metallica[metallica!= "Jason"]
metallica
metallica<-c(metallica, "Rob")
metallica
friends<-c(friends, "Mille", "Nina", "Kiri", "Jacob")
friends<-c("Mille","Nina","Kiri","Jacob")
friends
friends<-c("Mille","Nina","Kiri","Jacob")
friends<-friends[]
friends<-friends[!= "Jacob"]
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallica
metallica
friends
friends<-friends[friends != "Jacob]
"]
friends
friends<-friends[friends != "Jacob"]
friends
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica
metallica$Name
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age & minus metallica$childAge
metallica$fatherhoodAge<- metallica$Age & - metallica$childAge
fatherhoodAge
metallica
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
metallica
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
name<-c("Ben", "Martin", "Andy", "Paul", "Graham", "Carina", "Karina", "Doug", "Mark", "Zoe")
husband<-as.Date(c("1973-06-21", "1970-07-16", "1949-10-08", "1969-05-24"))
wife<-as.Date(c("1984-11-12", "1973-08-02", "1948-11-11", "1983-07-23"))
agegap<-husband-wife
agegap
birth_date<-as.Date(c("1977-07-03", "1969-05-24", "1973-06-21","1970-07-16", "1949-10-10", "1983-11-05", "1987-10-08", "1989-09-16","1973-05-20", "1984-11-12"))
job<-c(1,1,1,1,1,2,2,2,2,2)
job
job<-factor(job, levels = c(1:2), labels = c("Lecturer", "Student"))
job<-gl(2, 5, labels = c("Lecturer", "Student"))
levels(job)
levels(job)<-c("Medical Lecturer", "Medical Student")
friends<-c(5,2,0,4,1,10,12,15,12,17)
alcohol<-c(10,15,20,5,30,25,20,16,17,18)
income<-c(20000,40000,35000,22000,50000,5000,100,3000,10000,10)
neurotic<-c(10,17,14,13,21,7,13,9,14,13)
lecturerData<-data.frame(name,birth_date,job,friends,alcohol,income,neurotic)
lecturerData
lecturerPersonality <- lecturerData[, c("friends", "alcohol","neurotic")]
lecturerPersonality
lecturerOnly <- lecturerData[job=="Medical Lecturer",]
lecturerOnly
alcoholPersonality <- lecturerData[alcohol > 10, c("friends","alcohol", "neurotic")]
alcoholPersonality
alcoholPersonalityMatrix <- as.matrix(alcoholPersonality)
alcoholPersonalityMatrix
alcoholPersonalityMatrix <- as.matrix(lecturerData[alcohol > 10,c("friends", "alcohol", "neurotic")])
alcoholPersonalityMatrix
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat.txt", header = TRUE)
setwd("~/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio")
#Load data
search<- read.csv("~/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("~Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Remove NAs
search<-subset(search,search$rt!="NA")
search<-subset(search,search$correct_resp!=0)
#turn variables into factors
search$conjunct<-as.factor(search$conjunct)
search$present<-as.factor(search$present)
#Remove outliers
#search<-subset(search,search$rt<mean(search$rt)+3*sd(search$rt))
#histogram
hist(search$rt,breaks=10)
#Q-Q-plot
qqnorm(search$rt)
#make a log-transformation
search$logrt=log(search$rt)
#histogram
hist(search$logrt,breaks=10)
#Q-Q-plot
qqnorm(search$logrt)
search_model<-lm(logrt~setsize*conjunct*present, data=search)
summary(search_model)
library(ggplot2)
search$setsize_f<-as.factor(search$setsize)
ggplot(search, aes(x = setsize , y = rt, color=conjunct, fill=present)) +
geom_point() + labs(x = "setsize", y = "Response time)") +
geom_smooth(method='lm')
View(search)
sarah<- c(1.95,1.58,1.70,2.46,2.27,2.62,3.32,3.51,3.89,3.41)
mother<-c(3.21,4.04,3.30,3.85,4.13,4.59,4.11,4.29,5.82,5.14)
mean_sarah<-mean(sarah)
mean_mother<-mean(mother)
error_sarah<-sarah-mean_sarah
error_mother<-mother-mean_mother
error_sarah*error_mother
sum_of_scores<- sum(error_sarah*error_mother)
sum_of_scores
cov<-sum_of_scores/9
cov
SD_Sarah<-sqrt(mean_sarah)
cov
Correlation_coefficient<-cov/(0.82*0.79)
Correlation_coefficient
Correlation_coefficient*Correlation_coefficient
roh_squared<-Correlation_coefficient*Correlation_coefficient
Correlation_coefficient_aka_roh<-cov/(0.82*0.79)
install.packages("ggplot2"); install.packages("pastecs"); install.packages ("WRS")
library(ggplot2); library(pastecs); library(WRS)
install.packages ("WRS")
install.packages(“lme4”)
install.packages("lme4")
library(lme4)
politeness= read.csv("http://www.bodowinter.com/tutorial/politeness_data.csv")
View(politeness)
head(politeness)
tail(),
summary(politeness)
, str(),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness)
which(is.na(politeness$frequency))
which(!complete.cases(politeness))
boxplot(frequency ~ attitude*gender,
col=c("white","lightgray"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("white","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","lightpurple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
lmer(frequency ~ attitude, data=politeness)
politeness.model = lmer(frequency ~ attitude + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.null = lmer(frequency ~ gender +
(1|subject) + (1|scenario), data=politeness,
REML=FALSE)
politeness.null = lmer(frequency ~ gender + (1|subject) + (1|scenario), data=politeness,REML=FALSE)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
coef(politeness.model)
politeness.model = lmer(frequency ~ attitude +
gender + (1+attitude|subject) +
(1+attitude|scenario),
data=politeness,
REML=FALSE)
coef(politeness.model)
politeness.null = lmer(frequency ~ gender + (1+attitude|subject) + (1+attitude|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/portfolio 5")
library(lmerTest) ; library(boot) ; library(caret) ; library(mlogit) ; library(MuMIn) ; library(car) ; library(Rcmdr)
load("kikibobo.Rda")
# notice that echo = FALSE which means that this part of the analysis will not be visible in the report
###############################################
# This section creates a function called      #
# logisticPseudoR2s().  To use it             #
# type logisticPseudoR2s(myLogisticModel)     #
###############################################
logisticPseudoR2s <- function(LogModel) {
dev <- LogModel$deviance
nullDev <- LogModel$null.deviance
modelN <-  length(LogModel$fitted.values)
R.l <-  1 -  dev / nullDev
R.cs <- 1- exp ( -(nullDev - dev) / modelN)
R.n <- R.cs / ( 1 - ( exp (-(nullDev / modelN))))
cat("Pseudo R^2 for logistic regression\n")
cat("Hosmer and Lemeshow R^2  ", round(R.l, 3), "\n")
cat("Cox and Snell R^2        ", round(R.cs, 3), "\n")
cat("Nagelkerke R^2           ", round(R.n, 3),    "\n")}
# Here we get an insight into which type of figures we have the most of - in terms of size and shape - which will determine the baseline for R - The bigger amount will be set as baseline. That means that we´ll make predictions about how much more likely it is get big shapes compared to small and curved shapes compared to jagged - unless we relevel.
table(kikibobo$size)
"
big  sma
1917 2003
"
table(kikibobo$shape)
"
curved jagged
1822   2098
"
# Eventhough our hypothesis is that the vowel has an effect on the size, and vice versa, it might be interestring to see if consonants have an effect on size as well, so we include it as a predictor. Furthermore we´ll include (1|ID) as a random intercepts, beacuse we have a repeated measures design and people might differ in baseline.
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
"
Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.23894    0.05638  -4.238 2.25e-05 ***
vowelO       0.59059    0.06463   9.137  < 2e-16 ***
consonantK  -0.02296    0.06462  -0.355    0.722
"
# The vocal O
#Odds
exp(-0.23894+0.59059)
# odds are 1.421411
# Odds are above 1 - so we can expect that there is a higher probability of choosing a big model with vowel O
# The exact Probabilities
inv.logit(-0.23894+0.59059)
# the probabilities are 59% of choosing a big model when the vowel is an O
# The consonant K
#odds
exp(-0.23894+-0.02296)
# odds are 0.769588
#Probabilities
inv.logit(-0.23894+-0.02296)
# the probabilities are 44% of choosing a Big model when the consonant is an K
# But this probability is not significant
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
"
Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept)  0.57011    0.05829   9.780   <2e-16 ***
consonantK  -1.42233    0.06907 -20.592   <2e-16 ***
vowelO       0.60614    0.06899   8.786   <2e-16 ***
"
# The vocal O
#Odds
exp(0.57011+0.60614)
# odds are 3.242193
#Probabilities
inv.logit(0.57011+0.60614)
# the probabilities are 76% of choosing a curved model when the vowel is an O
# The consonant K
#odds
exp(0.57011-1.42233)
# odds are 0.4264671
#Probabilities
inv.logit(0.57011-1.42233)
# the probabilities are 30% of choosing a curved model when the consonant is an K
logisticPseudoR2s(model2)
# Here we get an insight into which type of figures we have the most of - in terms of size and shape - which will determine the baseline for R - The bigger amount will be set as baseline. That means that we´ll make predictions about how much more likely it is get big shapes compared to small and curved shapes compared to jagged - unless we relevel.
table(kikibobo$size)
"
big  sma
1917 2003
"
table(kikibobo$shape)
"
curved jagged
1822   2098
"
# Eventhough our hypothesis is that the vowel has an effect on the size, and vice versa, it might be interestring to see if consonants have an effect on size as well, so we include it as a predictor. Furthermore we´ll include (1|ID) as a random intercepts, beacuse we have a repeated measures design and people might differ in baseline.
model1 = glm(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
model1Chi <- model1$null.deviance - model1$deviance
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
exp(-0.25041+0.59057)
inv.logit(-0.25041+0.59057)
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
View(kikibobo)
model1.2 = glmer(size ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model1.2)
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
View(kikibobo)
model2.2 <- glmer(shape ~ vowel + (1|id), data = kikibobo, family = "binomial")
model2.2 <- glmer(shape ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model2.2)
exp(0.85460-1.39163)
inv.logit(0.85460-1.39163)
exp(-0.12465+0.53650)
inv.logit(-0.12465+0.53650)
kikibobo$size <- relevel(kikibobo$size, "sma")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
?relevel
View(kikibobo)
kikibobo$size <- relevel(kikibobo$size, "sma")
kikibobo$shape <- relevel(kikibobo$shape, "jagged")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
0.25041-0.59057
inv.logit(0.25041-0.59057)
model1.2 = glmer(size ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model1.2)
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
exp(-0.85460+1.39163)
inv.logit(-0.85460+1.39163)
model2.2 <- glmer(shape ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model2.2)
exp(0.12465-0.53650)
inv.logit(0.12465-0.53650)
knit_with_parameters('~/Google Drev/Hogwarts/R Studio/portfolios/portfolio 5/Portfolio5.Rmd', encoding = 'UTF-8')
setwd("/Users/FlowersnIce-cream/Downloads/exam/R-stuff")
library(tidyverse)
library(stringi)
library(stringr)
library(pastecs)
library(ggplot2)
setwd("/Users/FlowersnIce-cream/Downloads/exam/R-stuff/csvfiler/INFK")
filenames1 = list.files(pattern = "infk*") #creating a list of filenames
infk = data.frame() #creating an empty dataframe for importing data
for (i in filenames1){
file1 = read.csv(i)
infk = rbind(infk, file1)
}  #importing data from .csv files
infk$veg_koed<- "koed"
setwd("/Users/FlowersnIce-cream/Downloads/exam/R-stuff/csvfiler/INFV")
filenames2 = list.files(pattern = "infv*") #creating a list of filenames
infv = data.frame() #creating an empty dataframe for importing data
for (i in filenames2){
file2 = read.csv(i)
infv = rbind(infv, file2)
}  #importing data from .csv files
infv$veg_koed<- "veg"
setwd("/Users/FlowersnIce-cream/Downloads/exam/R-stuff/csvfiler/JPK")
filenames3 = list.files(pattern = "jpk*") #creating a list of filenames
jpk = data.frame() #creating an empty dataframe for importing data
for (i in filenames3){
file3 = read.csv(i)
jpk = rbind(jpk, file3)
}  #importing data from .csv files
jpk$veg_koed<- "koed"
setwd("/Users/FlowersnIce-cream/Downloads/exam/R-stuff/csvfiler/JPV")
filenames4 = list.files(pattern = "jpv*") #creating a list of filenames
jpv = data.frame() #creating an empty dataframe for importing data
for (i in filenames4){
file4 = read.csv(i)
jpv = rbind(jpv, file4)
}  #importing data from .csv files
jpv$veg_koed<- "veg"
ggplot(Collected, aes(x = år, y= a_score, colour = veg_koed)) +
geom_smooth(method = lm) +
geom_point() +
geom_smooth(se = FALSE, method = "lm")#+ facet_wrap(~veg_koed)
Collected <- rbind(jpv, jpk, infk, infv)
ggplot(Collected, aes(x = år, y= a_score, colour = veg_koed)) +
geom_smooth(method = lm) +
geom_point() +
geom_smooth(se = FALSE, method = "lm")#+ facet_wrap(~veg_koed)
ggplot(Collected, aes(x = år, y= a_score, colour = veg_koed)) +
geom_smooth(method = lm) +
geom_point() +
geom_smooth(se = FALSE, method = "lm")#+ facet_wrap(~veg_koed)
ggplot(Collected, aes(år, a_score, color = veg_koed, group=veg_koed))+
geom_point(stat = 'summary', fun.y=mean)+
stat_summary(fun.y=mean, geom="line", aes(group = veg_koed))+
geom_errorbar(stat='summary', fun.data= mean_se, width=0.1)+
labs(x = "Paper", y = "Mean Sentiment Score", color = "Party")
Collected <- rbind(jpv, jpk, infk, infv)
ggplot(Collected, aes(x = år, y= a_score, colour = veg_koed)) +
geom_smooth(method = lm) +
geom_point() +
geom_smooth(se = FALSE, method = "lm")#+ facet_wrap(~veg_koed)
ggplot(Collected, aes(år, a_score, color = veg_koed, group=veg_koed))+
geom_point(stat = 'summary', fun.y=mean)+
stat_summary(fun.y=mean, geom="line", aes(group = veg_koed))+
geom_errorbar(stat='summary', fun.data= mean_se, width=0.1)+
labs(x = "Paper", y = "Mean Sentiment Score", color = "Party")
collectedlm <- lm(Collected$a_score ~ Collected$veg_koed)
collectedlm
summary(collectedlm)
View(Collected)
scatter <- ggplot(Collected, aes(a_score, x..r))
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red")
View(file1)
View(infk)
scatter <- ggplot(Collected, aes(a_score, X..r))
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red")
scatter <- ggplot(Collected, aes(a_score, veg_koed))
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red")
scatter <- ggplot(Collected, aes(X..r, a_score))
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red")
View(Collected)
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red") + facet_wrap(veg_koed)
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red") + facet_wrap(veg_koed)
scatter + geom_point() + geom_smooth(method = "lm")
scatter + geom_point() + geom_smooth(mapping = NULL, data = NULL, stat = "smooth",
position = "identity", ..., method = "auto", formula = y ~ x,
se = TRUE, na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)
View(Collected)
collectedlm <- lm(Collected$a_score ~ Collected$veg_koed = "veg")
collectedlm <- lm(Collected$a_score ~ Collected$veg_koed)
summary(collectedlm)
